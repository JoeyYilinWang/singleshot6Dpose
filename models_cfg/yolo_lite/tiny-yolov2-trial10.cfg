[net]
# io
batch=16
height=416
width=416
channels=3
num_keypoints=9

# training
momentum=0.9
decay=0.0005
angle=0
burn_in=1000
max_batches = 80200
policy=steps
max_epochs=500
learning_rate=0.01
steps=-1,80,160
scales=0.1,0.1,0.1

# test - eliminate low confidence predictions during testing
conf_thresh= 0.1
test_width=672
test_height=672

# data augmentation
saturation = 1.5
exposure = 1.5
hue=.1

[convolutional]
batch_normalize=0
filters=16
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=0
filters=32
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=0
filters=64
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=0
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2


[convolutional]
batch_normalize=0
filters=128
size=3
stride=1
pad=1
activation=leaky

[maxpool]
size=2
stride=2

###########

[convolutional]
batch_normalize=0
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
# filters=125
filters=20
activation=linear

[region]
# anchors =  1.3221, 1.73145, 3.19275, 4.00944, 5.05587, 8.09892, 9.47112, 4.84053, 11.2364, 10.0071
anchors = 
bias_match=1
classes=1
coords=18
num=1
softmax=1
jitter=.3
rescore=1

object_scale=5
noobject_scale=0.1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
